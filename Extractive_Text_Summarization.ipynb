{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Extractive_Text_Summarization.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Text Summarization Python helps in summarizing and shortening the text in the user feedback.**"
      ],
      "metadata": {
        "id": "2QiX2NzE-gpu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use extractive method. This method functions by identifying important sentences or excerpts from the text and reproducing them as part of the summary. In this approach, no new text is generated, only the existing text is used in the summarization process. \n",
        "\n"
      ],
      "metadata": {
        "id": "SYP5fRql_X1s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"There are many techniques available to generate extractive summarization to keep it simple. \n",
        "I will be using an unsupervised learning approach to find the sentences similarity and rank them \n",
        "Summarization can be detined as a task or producing a concise and fluent summary while preserving key\n",
        "information and overall meaning. One benefit of this will be, you don't need to train and build a model \n",
        "prior start using it for your project. It's good ta understand Cosine similarity to make the best use of\n",
        "the code you are going to see. Cosine similarity is a measure of similaritv between two non-zero vectors\n",
        "of an inner product space that measures the cosine or the angle between them. Its measures cosine or the\n",
        "angle between vectors. The angle will be 0 if sentences are similar \"\"\"\n"
      ],
      "metadata": {
        "id": "KbXMWjprwbyc"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize"
      ],
      "metadata": {
        "id": "VjSvGPCEwUtX"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "md6XsqGtwuxf",
        "outputId": "0aa56424-d8d8-4a53-cc79-aaa29b6f9b56"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stopWords= set(stopwords.words(\"english\"))"
      ],
      "metadata": {
        "id": "OSN6ZE94wkfW"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stopWords"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s9-3XmoW9p2A",
        "outputId": "f795e914-b86e-41a8-8d55-730936e9d1de"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'a',\n",
              " 'about',\n",
              " 'above',\n",
              " 'after',\n",
              " 'again',\n",
              " 'against',\n",
              " 'ain',\n",
              " 'all',\n",
              " 'am',\n",
              " 'an',\n",
              " 'and',\n",
              " 'any',\n",
              " 'are',\n",
              " 'aren',\n",
              " \"aren't\",\n",
              " 'as',\n",
              " 'at',\n",
              " 'be',\n",
              " 'because',\n",
              " 'been',\n",
              " 'before',\n",
              " 'being',\n",
              " 'below',\n",
              " 'between',\n",
              " 'both',\n",
              " 'but',\n",
              " 'by',\n",
              " 'can',\n",
              " 'couldn',\n",
              " \"couldn't\",\n",
              " 'd',\n",
              " 'did',\n",
              " 'didn',\n",
              " \"didn't\",\n",
              " 'do',\n",
              " 'does',\n",
              " 'doesn',\n",
              " \"doesn't\",\n",
              " 'doing',\n",
              " 'don',\n",
              " \"don't\",\n",
              " 'down',\n",
              " 'during',\n",
              " 'each',\n",
              " 'few',\n",
              " 'for',\n",
              " 'from',\n",
              " 'further',\n",
              " 'had',\n",
              " 'hadn',\n",
              " \"hadn't\",\n",
              " 'has',\n",
              " 'hasn',\n",
              " \"hasn't\",\n",
              " 'have',\n",
              " 'haven',\n",
              " \"haven't\",\n",
              " 'having',\n",
              " 'he',\n",
              " 'her',\n",
              " 'here',\n",
              " 'hers',\n",
              " 'herself',\n",
              " 'him',\n",
              " 'himself',\n",
              " 'his',\n",
              " 'how',\n",
              " 'i',\n",
              " 'if',\n",
              " 'in',\n",
              " 'into',\n",
              " 'is',\n",
              " 'isn',\n",
              " \"isn't\",\n",
              " 'it',\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'itself',\n",
              " 'just',\n",
              " 'll',\n",
              " 'm',\n",
              " 'ma',\n",
              " 'me',\n",
              " 'mightn',\n",
              " \"mightn't\",\n",
              " 'more',\n",
              " 'most',\n",
              " 'mustn',\n",
              " \"mustn't\",\n",
              " 'my',\n",
              " 'myself',\n",
              " 'needn',\n",
              " \"needn't\",\n",
              " 'no',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'now',\n",
              " 'o',\n",
              " 'of',\n",
              " 'off',\n",
              " 'on',\n",
              " 'once',\n",
              " 'only',\n",
              " 'or',\n",
              " 'other',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'out',\n",
              " 'over',\n",
              " 'own',\n",
              " 're',\n",
              " 's',\n",
              " 'same',\n",
              " 'shan',\n",
              " \"shan't\",\n",
              " 'she',\n",
              " \"she's\",\n",
              " 'should',\n",
              " \"should've\",\n",
              " 'shouldn',\n",
              " \"shouldn't\",\n",
              " 'so',\n",
              " 'some',\n",
              " 'such',\n",
              " 't',\n",
              " 'than',\n",
              " 'that',\n",
              " \"that'll\",\n",
              " 'the',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'them',\n",
              " 'themselves',\n",
              " 'then',\n",
              " 'there',\n",
              " 'these',\n",
              " 'they',\n",
              " 'this',\n",
              " 'those',\n",
              " 'through',\n",
              " 'to',\n",
              " 'too',\n",
              " 'under',\n",
              " 'until',\n",
              " 'up',\n",
              " 've',\n",
              " 'very',\n",
              " 'was',\n",
              " 'wasn',\n",
              " \"wasn't\",\n",
              " 'we',\n",
              " 'were',\n",
              " 'weren',\n",
              " \"weren't\",\n",
              " 'what',\n",
              " 'when',\n",
              " 'where',\n",
              " 'which',\n",
              " 'while',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'why',\n",
              " 'will',\n",
              " 'with',\n",
              " 'won',\n",
              " \"won't\",\n",
              " 'wouldn',\n",
              " \"wouldn't\",\n",
              " 'y',\n",
              " 'you',\n",
              " \"you'd\",\n",
              " \"you'll\",\n",
              " \"you're\",\n",
              " \"you've\",\n",
              " 'your',\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves'}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = word_tokenize(text)\n",
        "words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kOo1AwcvFMCC",
        "outputId": "a28ae145-cdbc-4860-c947-bec8fdee9dbb"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['There',\n",
              " 'are',\n",
              " 'many',\n",
              " 'techniques',\n",
              " 'available',\n",
              " 'to',\n",
              " 'generate',\n",
              " 'extractive',\n",
              " 'summarization',\n",
              " 'to',\n",
              " 'keep',\n",
              " 'it',\n",
              " 'simple',\n",
              " '.',\n",
              " 'I',\n",
              " 'will',\n",
              " 'be',\n",
              " 'using',\n",
              " 'an',\n",
              " 'unsupervised',\n",
              " 'learning',\n",
              " 'approach',\n",
              " 'to',\n",
              " 'find',\n",
              " 'the',\n",
              " 'sentences',\n",
              " 'similarity',\n",
              " 'and',\n",
              " 'rank',\n",
              " 'them',\n",
              " 'Summarization',\n",
              " 'can',\n",
              " 'be',\n",
              " 'detined',\n",
              " 'as',\n",
              " 'a',\n",
              " 'task',\n",
              " 'or',\n",
              " 'producing',\n",
              " 'a',\n",
              " 'concise',\n",
              " 'and',\n",
              " 'fluent',\n",
              " 'summary',\n",
              " 'while',\n",
              " 'preserving',\n",
              " 'key',\n",
              " 'information',\n",
              " 'and',\n",
              " 'overall',\n",
              " 'meaning',\n",
              " '.',\n",
              " 'One',\n",
              " 'benefit',\n",
              " 'of',\n",
              " 'this',\n",
              " 'will',\n",
              " 'be',\n",
              " ',',\n",
              " 'you',\n",
              " 'do',\n",
              " \"n't\",\n",
              " 'need',\n",
              " 'to',\n",
              " 'train',\n",
              " 'and',\n",
              " 'build',\n",
              " 'a',\n",
              " 'model',\n",
              " 'prior',\n",
              " 'start',\n",
              " 'using',\n",
              " 'it',\n",
              " 'for',\n",
              " 'your',\n",
              " 'project',\n",
              " '.',\n",
              " 'It',\n",
              " \"'s\",\n",
              " 'good',\n",
              " 'ta',\n",
              " 'understand',\n",
              " 'Cosine',\n",
              " 'similarity',\n",
              " 'to',\n",
              " 'make',\n",
              " 'the',\n",
              " 'best',\n",
              " 'use',\n",
              " 'of',\n",
              " 'the',\n",
              " 'code',\n",
              " 'you',\n",
              " 'are',\n",
              " 'going',\n",
              " 'to',\n",
              " 'see',\n",
              " '.',\n",
              " 'Cosine',\n",
              " 'similarity',\n",
              " 'is',\n",
              " 'a',\n",
              " 'measure',\n",
              " 'of',\n",
              " 'similaritv',\n",
              " 'between',\n",
              " 'two',\n",
              " 'non-zero',\n",
              " 'vectors',\n",
              " 'of',\n",
              " 'an',\n",
              " 'inner',\n",
              " 'product',\n",
              " 'space',\n",
              " 'that',\n",
              " 'measures',\n",
              " 'the',\n",
              " 'cosine',\n",
              " 'or',\n",
              " 'the',\n",
              " 'angle',\n",
              " 'between',\n",
              " 'them',\n",
              " '.',\n",
              " 'Its',\n",
              " 'measures',\n",
              " 'cosine',\n",
              " 'or',\n",
              " 'the',\n",
              " 'angle',\n",
              " 'between',\n",
              " 'vectors',\n",
              " '.',\n",
              " 'The',\n",
              " 'angle',\n",
              " 'will',\n",
              " 'be',\n",
              " '0',\n",
              " 'if',\n",
              " 'sentences',\n",
              " 'are',\n",
              " 'similar']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "freqTable = dict()\n",
        "\n",
        "for word in words:\n",
        "  word = word.lower()\n",
        "  if word in stopWords:\n",
        "    continue\n",
        "  if word in freqTable:\n",
        "    freqTable[word] += 1\n",
        "  else: \n",
        "    freqTable[word] = 1\n",
        "sentences = sent_tokenize(text)\n",
        "sentenceValue = dict()"
      ],
      "metadata": {
        "id": "xGzPpcD_xDZR"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "freqTable"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FTfBSW2dLb_l",
        "outputId": "a3c9117a-59c6-478a-c090-64e0f047b4f3"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{\"'s\": 1,\n",
              " ',': 1,\n",
              " '.': 6,\n",
              " '0': 1,\n",
              " 'angle': 3,\n",
              " 'approach': 1,\n",
              " 'available': 1,\n",
              " 'benefit': 1,\n",
              " 'best': 1,\n",
              " 'build': 1,\n",
              " 'code': 1,\n",
              " 'concise': 1,\n",
              " 'cosine': 4,\n",
              " 'detined': 1,\n",
              " 'extractive': 1,\n",
              " 'find': 1,\n",
              " 'fluent': 1,\n",
              " 'generate': 1,\n",
              " 'going': 1,\n",
              " 'good': 1,\n",
              " 'information': 1,\n",
              " 'inner': 1,\n",
              " 'keep': 1,\n",
              " 'key': 1,\n",
              " 'learning': 1,\n",
              " 'make': 1,\n",
              " 'many': 1,\n",
              " 'meaning': 1,\n",
              " 'measure': 1,\n",
              " 'measures': 2,\n",
              " 'model': 1,\n",
              " \"n't\": 1,\n",
              " 'need': 1,\n",
              " 'non-zero': 1,\n",
              " 'one': 1,\n",
              " 'overall': 1,\n",
              " 'preserving': 1,\n",
              " 'prior': 1,\n",
              " 'producing': 1,\n",
              " 'product': 1,\n",
              " 'project': 1,\n",
              " 'rank': 1,\n",
              " 'see': 1,\n",
              " 'sentences': 2,\n",
              " 'similar': 1,\n",
              " 'similaritv': 1,\n",
              " 'similarity': 3,\n",
              " 'simple': 1,\n",
              " 'space': 1,\n",
              " 'start': 1,\n",
              " 'summarization': 2,\n",
              " 'summary': 1,\n",
              " 'ta': 1,\n",
              " 'task': 1,\n",
              " 'techniques': 1,\n",
              " 'train': 1,\n",
              " 'two': 1,\n",
              " 'understand': 1,\n",
              " 'unsupervised': 1,\n",
              " 'use': 1,\n",
              " 'using': 2,\n",
              " 'vectors': 2}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qc-aysqHQ4P",
        "outputId": "d00edc09-e4fe-44d7-dc0b-c200d90b9e50"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['There are many techniques available to generate extractive summarization to keep it simple.',\n",
              " 'I will be using an unsupervised learning approach to find the sentences similarity and rank them \\nSummarization can be detined as a task or producing a concise and fluent summary while preserving key\\ninformation and overall meaning.',\n",
              " \"One benefit of this will be, you don't need to train and build a model \\nprior start using it for your project.\",\n",
              " \"It's good ta understand Cosine similarity to make the best use of\\nthe code you are going to see.\",\n",
              " 'Cosine similarity is a measure of similaritv between two non-zero vectors\\nof an inner product space that measures the cosine or the angle between them.',\n",
              " 'Its measures cosine or the\\nangle between vectors.',\n",
              " 'The angle will be 0 if sentences are similar']"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentenceValue"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xivbcJfNHWzD",
        "outputId": "de5aef0f-9c62-4567-baed-738ad86a8800"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Cosine similarity is a measure of similaritv between two non-zero vectors\\nof an inner product space that measures the cosine or the angle between them.': 28,\n",
              " 'I will be using an unsupervised learning approach to find the sentences similarity and rank them \\nSummarization can be detined as a task or producing a concise and fluent summary while preserving key\\ninformation and overall meaning.': 33,\n",
              " \"It's good ta understand Cosine similarity to make the best use of\\nthe code you are going to see.\": 24,\n",
              " 'Its measures cosine or the\\nangle between vectors.': 18,\n",
              " \"One benefit of this will be, you don't need to train and build a model \\nprior start using it for your project.\": 20,\n",
              " 'The angle will be 0 if sentences are similar': 7,\n",
              " 'There are many techniques available to generate extractive summarization to keep it simple.': 15}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for sentence in sentences:\n",
        "  for word, freq in freqTable.items():\n",
        "    if word in sentence.lower():\n",
        "      if sentence in sentenceValue:\n",
        "        sentenceValue[sentence] += freq\n",
        "      else:\n",
        "        sentenceValue[sentence] = freq\n",
        "\n",
        "sumValues = 0\n",
        "for sentence in sentenceValue:\n",
        "  sumValues += sentenceValue[ sentence]\n",
        "\n",
        "# Average value of a sentence from the original text\n",
        "\n",
        "average = int (sumValues / len (sentenceValue))\n",
        "\n",
        "# Storing sentences into our summary.\n",
        "summary = ''\n",
        "for sentence in sentences:\n",
        "  if (sentence in sentenceValue) and (sentenceValue[sentence] > (1.2 * average)):\n",
        "      summary += \" \" + sentence\n",
        "\n",
        "print (summary)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Khyy7IHlx3bv",
        "outputId": "521bb28e-dbc1-4c16-9395-bb2869897c15"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " I will be using an unsupervised learning approach to find the sentences similarity and rank them \n",
            "Summarization can be detined as a task or producing a concise and fluent summary while preserving key\n",
            "information and overall meaning. Cosine similarity is a measure of similaritv between two non-zero vectors\n",
            "of an inner product space that measures the cosine or the angle between them.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116
        },
        "id": "DtBQchEMyqSz",
        "outputId": "990b744a-b951-4338-9a4e-2b466ee281b0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"There are many techniques available to generate extractive summarization to keep it simple. \\nI will be using an unsupervised learning approach to find the sentences similarity and rank them \\nSummarization can be detined as a task or producing a concise and fluent summary while preserving key\\ninformation and overall meaning. One benefit of this will be, you don't need to train and build a model \\nprior start using it for your project. It's good ta understand Cosine similarity to make the best use of\\nthe code you are going to see. Cosine similarity is a measure of similaritv between two non-zero vectors\\nof an inner product space that measures the cosine or the angle between them. Its measures cosine or the\\nangle between vectors. The angle will be 0 if sentences are similar \""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "OkV_FffqyzbR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Text Summarization Using Gensim Library**"
      ],
      "metadata": {
        "id": "I3fC3GlkZlB_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.summarization.summarizer import summarize\n",
        "from gensim.summarization import keywords"
      ],
      "metadata": {
        "id": "t-kjD2puYaoO"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(keywords(text, words=8))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wSLLOm1kYsl3",
        "outputId": "cfae19b1-81e8-404b-e450-00806f2056e4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cosine\n",
            "extractive\n",
            "key\n",
            "learning\n",
            "product\n",
            "prior\n",
            "similarity\n",
            "similar\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(summarize(text, ratio=0.5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WYbvvZGwYm4T",
        "outputId": "453ee86d-6122-4845-8be4-1a425403964a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are many techniques available to generate extractive summarization to keep it simple.\n",
            "Summarization can be detined as a task or producing a concise and fluent summary while preserving key\n",
            "Cosine similarity is a measure of similaritv between two non-zero vectors\n",
            "of an inner product space that measures the cosine or the angle between them.\n",
            "Its measures cosine or the\n",
            "The angle will be 0 if sentences are similar \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "IuiSFfE-ZZE7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}